# ðŸ“Š Guide Analyste de DonnÃ©es - PRISMA Review Manager

Ce document technique dÃ©taille les mÃ©thodologies statistiques, les algorithmes de NLP et les structures de donnÃ©es utilisÃ©s dans PRISMA Review Manager. Il est destinÃ© aux Data Scientists, BibliomÃ©triciens et Analystes.

---

## ðŸ§  MÃ©thodologie Algorithmique & Statistique

### 1. Recherche Hybride (Hybrid Search)

Le classement des articles utilise une approche hybride combinant **Recherche SÃ©mantique** (sens) et **Recherche Lexicale** (mots-clÃ©s exacts).

$$ Score_{final} = \alpha \cdot \text{Norm}(S_{sem}) + (1-\alpha) \cdot \text{Norm}(S_{lex}) $$
*Avec $\alpha = 0.7$ (poids prÃ©pondÃ©rant Ã  la sÃ©mantique).*

#### A. Score SÃ©mantique (Bi-Encoder)
Chaque article $D$ est dÃ©coupÃ© en segments (chunks) $c_i$ de taille fixe (400 mots).
Le score $S_{sem}$ est la similaritÃ© cosinus maximale (Max Pooling) entre l'embedding de la requÃªte $\mathbf{v}_Q$ et les embeddings des chunks :

$$ S_{sem}(D, Q) = \max_{i} \left( \frac{\mathbf{v}_Q \cdot \mathbf{v}_{c_i}}{\|\mathbf{v}_Q\| \|\mathbf{v}_{c_i}\|} \right) $$

**ModÃ¨le :** `paraphrase-MiniLM-L3-v2` (384 dimensions).

#### B. Score Lexical (BM25)
Utilise l'algorithme **BM25Okapi** pour capturer la frÃ©quence des termes exacts, ce qui est crucial pour les acronymes ou termes techniques spÃ©cifiques que le modÃ¨le sÃ©mantique pourrait manquer.

$$ S_{lex}(D, Q) = \sum_{q \in Q} \text{IDF}(q) \cdot \frac{f(q, D) \cdot (k_1 + 1)}{f(q, D) + k_1 \cdot (1 - b + b \cdot \frac{|D|}{\text{avgdl}})} $$

**ParamÃ¨tres standards :** $k_1 = 1.5$, $b = 0.75$.

#### C. Normalisation & Fusion
Les scores bruts (Cosinus [-1, 1] et BM25 [0, $\infty$]) sont normalisÃ©s par **Min-Max Scaling** avant la fusion linÃ©aire pour garantir une contribution Ã©quilibrÃ©e.

### 2. Suggestion de Seuil (Gaussian Mixture Model)

Pour suggÃ©rer automatiquement un seuil de coupure (threshold) entre articles pertinents et non-pertinents, nous utilisons une approche non-supervisÃ©e basÃ©e sur un **ModÃ¨le de MÃ©lange Gaussien (GMM)**.

On suppose que la distribution des scores de similaritÃ© $S$ suit un mÃ©lange de deux distributions normales (bimodale) :
1.  Distribution du bruit (articles non pertinents) : $\mathcal{N}(\mu_0, \sigma_0^2)$
2.  Distribution du signal (articles pertinents) : $\mathcal{N}(\mu_1, \sigma_1^2)$ avec $\mu_1 > \mu_0$.

Le seuil optimal $T$ est estimÃ© par la moyenne des espÃ©rances :
$$ T \approx \frac{\mu_0 + \mu_1}{2} $$

*Note : Si le GMM ne converge pas (trop peu de donnÃ©es), la mÃ©diane est utilisÃ©e comme fallback robuste.*

### 3. Classification Zero-Shot (Cross-Encoder)

Pour la vÃ©rification des critÃ¨res d'exclusion (ex: "Animal Study"), nous utilisons un modÃ¨le **Cross-Encoder** (`ms-marco-TinyBERT-L-2-v2`). Contrairement au Bi-Encoder, ce modÃ¨le prend en entrÃ©e la paire concatÃ©nÃ©e (Texte, CritÃ¨re) et prÃ©dit directement un score d'entailment (logit).

$$ \text{Logit}(D, C) = f_{\theta}(\text{concat}(D, C)) $$

**Seuil de dÃ©cision :** CalibrÃ© empiriquement Ã  **-11.0** (logits bruts) pour maximiser le rappel (Recall) et minimiser les Faux NÃ©gatifs lors du screening.

---

## ðŸ”„ Flux de DonnÃ©es & ETL

### Pipeline d'Ingestion
1.  **Raw Data** : JSON/XML provenant des APIs (arXiv, PubMed).
2.  **Normalization** : Nettoyage Unicode (`ftfy`), dÃ©tection de langue.
3.  **Deduplication** :
    *   ClÃ© primaire stricte : `DOI` (si disponible).
    *   ClÃ© floue : `NormalizedTitle` (minuscules, sans ponctuation).
    *   $$ \text{norm}(t) = \text{lower}(\text{remove\_punctuation}(t)) $$

### MÃ©triques de Performance (KPIs)

| MÃ©trique | Formule | InterprÃ©tation |
| :--- | :--- | :--- |
| **Inclusion Rate** | $N_{included} / N_{identified}$ | SpÃ©cificitÃ© de la requÃªte initiale. Cible : 1-5% pour revues larges. |
| **Screening Efficiency** | $N_{screened\_out} / \Delta t$ | Vitesse de tri (articles/heure). |
| **Inter-Rater Agreement** | (PrÃ©vu v2) Kappa de Cohen | Accord entre plusieurs reviewers. |

---

## ðŸ’¾ SchÃ©ma de DonnÃ©es & Exports

### Structure SQL (Relationnelle)
Le schÃ©ma est normalisÃ© (3NF) pour garantir l'intÃ©gritÃ©.
*   `articles` (Table de faits)
*   `search_sessions` (Dimension Temps/RequÃªte)
*   `article_history` (Dimension Audit/Log)

### Exports pour Analyse AvancÃ©e

#### 1. JSON Complet (Pour NLP/ML)
Contient les structures imbriquÃ©es et les mÃ©tadonnÃ©es IA.
```json
{
  "id": 123,
  "title": "Deep Learning...",
  "ia_metadata": {
    "model": "paraphrase-MiniLM-L3-v2",
    "criteria_scores": {"Animal Study": -8.4, "Review": -12.1}
  },
  "history": [...]
}
```

#### 2. CSV Plat (Pour Excel/Tableau/PowerBI)
Aplatit les donnÃ©es pour l'analyse pivot.
*   `ia_score` : Score de pertinence (float).
*   `decision_final` : Statut final (catÃ©gorique).

---

## ðŸ› ï¸ Outils RecommandÃ©s

Pour explorer la base de donnÃ©es `prisma.db` (SQLite) :
*   **Python** : `pandas.read_sql("SELECT * FROM articles", con)`
*   **R** : `RSQLite` pour l'analyse bibliomÃ©trique (`bibliometrix`).
*   **SQL** : RequÃªtes directes pour agrÃ©gations complexes.

**Exemple d'analyse de tendance (SQL) :**
```sql
-- Taux d'inclusion par annÃ©e
SELECT 
    year,
    COUNT(*) as total,
    SUM(CASE WHEN status = 'INCLUDED' THEN 1 ELSE 0 END) as included,
    ROUND(AVG(relevance_score), 3) as avg_ai_score
FROM articles
GROUP BY year
HAVING total > 5
ORDER BY year DESC;
```
