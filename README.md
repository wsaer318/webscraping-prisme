# ğŸ”¬ Pipeline AvancÃ© de Tri d'Articles Scientifiques

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue.svg)](https://www.python.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Code Style](https://img.shields.io/badge/Code%20Style-Black-black.svg)](https://github.com/psf/black)

Un systÃ¨me intelligent et robuste de filtrage, tri et sÃ©lection d'articles scientifiques utilisant l'apprentissage automatique, le traitement du langage naturel (NLP) et des techniques statistiques avancÃ©es.

---

## ğŸ“‹ Table des MatiÃ¨res

- [Vue d'ensemble](#-vue-densemble)
- [FonctionnalitÃ©s](#-fonctionnalitÃ©s)
- [Architecture](#-architecture)
- [Installation](#-installation)
- [Utilisation](#-utilisation)
- [Structure du Projet](#-structure-du-projet)
- [Configuration](#-configuration)
- [RÃ©sultats et Visualisations](#-rÃ©sultats-et-visualisations)
- [Technologies UtilisÃ©es](#-technologies-utilisÃ©es)
- [Contribution](#-contribution)
- [License](#-license)

---

## ğŸ¯ Vue d'ensemble

Ce pipeline implÃ©mente un systÃ¨me de bout-en-bout pour :
- **Filtrer** et nettoyer des articles scientifiques
- **Scorer** leur pertinence par rapport Ã  une requÃªte
- **DÃ©tecter** les doublons et quasi-doublons
- **Clusteriser** les articles par similaritÃ© sÃ©mantique
- **SÃ©lectionner** les meilleurs articles en optimisant la diversitÃ© et la pertinence
- **Visualiser** les rÃ©sultats avec des graphiques interactifs

Le systÃ¨me est conÃ§u pour Ãªtre **robuste**, **sÃ©curisÃ©** et **scalable**, avec une attention particuliÃ¨re portÃ©e Ã  la validation statistique et Ã  la qualitÃ© du code.

---

## âœ¨ FonctionnalitÃ©s

### ğŸ” Analyse et Filtrage
- **Nettoyage robuste** : Sanitisation HTML, normalisation Unicode, dÃ©tection de langue
- **DÃ©tection de doublons** : Identification des doublons exacts et quasi-doublons par hashing et similaritÃ©
- **Validation de sÃ©curitÃ©** : Protection contre XSS, injection SQL, attaques DoS

### ğŸ“Š Scoring Multi-CritÃ¨res
- **BM25** : Score de pertinence lexicale
- **Embeddings sÃ©mantiques** : SimilaritÃ© cosinus avec Sentence-BERT
- **Scores combinÃ©s** : Z-scores robustes utilisant la dÃ©viation mÃ©diane absolue (MAD)

### ğŸ² Clustering Intelligent
- **DBSCAN** : Clustering avec epsilon adaptatif
- **HDBSCAN** : Clustering hiÃ©rarchique robuste (optionnel)
- **MÃ©triques de qualitÃ©** : Silhouette, Calinski-Harabasz, Davies-Bouldin

### ğŸ¯ SÃ©lection Optimale
- **Seuillage multi-mÃ©thode** : GMM, KDE, Otsu, mÃ©thode d'ensemble
- **MMR (Maximal Marginal Relevance)** : Optimisation pertinence/diversitÃ©
- **Facility Location** : SÃ©lection submodulaire pour reprÃ©sentativitÃ© maximale

### ğŸ“ˆ Visualisations
- Distributions des scores
- Analyse des seuils
- Diagrammes de flux (pipeline)
- Projections 2D/3D des embeddings
- Heatmaps de similaritÃ©
- Graphiques radar de qualitÃ©

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Articles CSV   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Preprocessing  â”‚ â† Nettoyage, normalisation, validation
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Embeddings    â”‚ â† Sentence-BERT (modÃ¨le multilingue)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Scoring     â”‚ â† BM25 + SimilaritÃ© sÃ©mantique
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Deduplication  â”‚ â† DÃ©tection doublons/quasi-doublons
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Clustering    â”‚ â† DBSCAN/HDBSCAN
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Thresholding   â”‚ â† Seuillage adaptatif multi-mÃ©thode
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      MMR        â”‚ â† SÃ©lection finale optimale
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    RÃ©sultats    â”‚ â† CSV + JSON + Visualisations
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ Installation

### PrÃ©requis
- **Python** : 3.8 ou supÃ©rieur
- **RAM** : Minimum 8 GB (16 GB recommandÃ© pour gros corpus)
- **SystÃ¨me** : Windows 10+, Linux, macOS

### Installation des dÃ©pendances

```bash
# CrÃ©er un environnement virtuel (recommandÃ©)
python -m venv venv

# Activer l'environnement
# Windows
venv\Scripts\activate
# Linux/macOS
source venv/bin/activate

# Installer les dÃ©pendances
pip install -r requirements_improved.txt
```

### Installation rapide (dÃ©pendances minimales)

```bash
pip install numpy pandas scipy scikit-learn torch sentence-transformers rank-bm25 langdetect ftfy
```

---

## ğŸ’» Utilisation

### GÃ©nÃ©ration de donnÃ©es de test

```bash
python generate_data.py --n-pos 200 --n-neg 150 --seed 42 --out articles_fictifs.csv
```

### ExÃ©cution du pipeline

```python
from process_improved import ArticlePipeline, PipelineConfig

# Configuration
config = PipelineConfig(
    query_main="intelligence artificielle machine learning",
    threshold_method="ensemble",
    cluster_method="dbscan",
    mmr_topk=50,
    mmr_lambda=0.7
)

# Initialisation et exÃ©cution
pipeline = ArticlePipeline(config)
pipeline.load_data("articles_fictifs.csv")
df_final = pipeline.run()

# Sauvegarde des rÃ©sultats
pipeline.save_results("articles_final.csv", "articles_report.json")
```

### GÃ©nÃ©ration des visualisations

```bash
python generate_visualizations.py
```

Les visualisations seront gÃ©nÃ©rÃ©es dans le dossier `visualizations/`.

---

## ğŸ“ Structure du Projet

```
projet_filtre/
â”œâ”€â”€ ğŸ“„ README.md                          # Documentation principale
â”œâ”€â”€ ğŸ“„ requirements_improved.txt          # DÃ©pendances Python
â”œâ”€â”€ ğŸ generate_data.py                   # GÃ©nÃ©rateur d'articles fictifs
â”œâ”€â”€ ğŸ process_improved.py                # Pipeline principal (cÅ“ur du systÃ¨me)
â”œâ”€â”€ ğŸ generate_visualizations.py         # Script de gÃ©nÃ©ration de graphiques
â”œâ”€â”€ ğŸ visualize.py                       # Utilitaires de visualisation
â”œâ”€â”€ ğŸ“Š articles_fictifs.csv               # DonnÃ©es d'entrÃ©e (exemple)
â”œâ”€â”€ ğŸ“Š articles_final.csv                 # RÃ©sultats finaux
â”œâ”€â”€ ğŸ“Š articles_final_embeddings.npy      # Embeddings sauvegardÃ©s
â”œâ”€â”€ ğŸ“‹ articles_report.json               # Rapport dÃ©taillÃ© JSON
â”œâ”€â”€ ğŸ“ pipeline.log                       # Logs d'exÃ©cution
â””â”€â”€ ğŸ“ visualizations/                    # Graphiques gÃ©nÃ©rÃ©s
    â”œâ”€â”€ 01_score_distributions.png
    â”œâ”€â”€ 02_threshold_analysis.png
    â”œâ”€â”€ 03_pipeline_flow.png
    â”œâ”€â”€ 04_clusters_2d.png
    â”œâ”€â”€ 05_top_articles.png
    â”œâ”€â”€ 06_score_correlation.png
    â”œâ”€â”€ 07_similarity_heatmap.png
    â”œâ”€â”€ 08_text_lengths.png
    â”œâ”€â”€ 09_cluster_boxplots.png
    â”œâ”€â”€ 10_quality_radar.png
    â”œâ”€â”€ 11_score_table.png
    â”œâ”€â”€ 12_embeddings_3d.png
    â””â”€â”€ README.md
```

---

## âš™ï¸ Configuration

Le pipeline est hautement configurable via la classe `PipelineConfig` :

### ParamÃ¨tres principaux

| ParamÃ¨tre | Description | Valeurs | DÃ©faut |
|-----------|-------------|---------|--------|
| `query_main` | RequÃªte de recherche principale | string | `""` |
| `threshold_method` | MÃ©thode de seuillage | `"ensemble"`, `"gmm"`, `"kde"`, `"otsu"` | `"ensemble"` |
| `cluster_method` | Algorithme de clustering | `"dbscan"`, `"hdbscan"` | `"dbscan"` |
| `mmr_topk` | Nombre d'articles finaux | int | `50` |
| `mmr_lambda` | Balance pertinence/diversitÃ© | 0.0-1.0 | `0.7` |
| `min_abstract_len` | Longueur minimale d'abstract | int | `50` |
| `dedup_threshold` | Seuil de dÃ©duplication | 0.0-1.0 | `0.95` |

### Limites de sÃ©curitÃ©

```python
config.max_text_len = 50000        # Limite contre attaques DoS
config.max_embedding_batch = 256   # Taille de batch pour embeddings
config.sanitize_html = True        # Nettoyage HTML actif
```

---

## ğŸ“Š RÃ©sultats et Visualisations

### Fichiers de sortie

#### `articles_final.csv`
Articles sÃ©lectionnÃ©s avec scores et mÃ©tadonnÃ©es :
- `url`, `title`, `abstract`, `body`
- `bm25_score`, `semantic_score`, `combined_score`
- `cluster_id`, `is_cluster_rep`
- `mmr_score`, `rank`

#### `articles_report.json`
Rapport dÃ©taillÃ© incluant :
- Statistiques globales
- MÃ©triques de clustering
- Analyse de sensibilitÃ©
- Diagnostics statistiques
- Logs d'exÃ©cution

### Visualisations disponibles

1. **Distributions des scores** : Histogrammes BM25, sÃ©mantique, combinÃ©
2. **Analyse des seuils** : MÃ©thodes de seuillage comparÃ©es
3. **Pipeline flow** : Diagramme de flux Sankey
4. **Clusters 2D** : Projection t-SNE/UMAP
5. **Top articles** : Barres horizontales des meilleurs scores
6. **CorrÃ©lations** : Scatter plots entre scores
7. **Heatmap de similaritÃ©** : Matrice de similaritÃ© sÃ©mantique
8. **Longueurs de texte** : Distribution des longueurs
9. **Boxplots par cluster** : Scores par cluster
10. **Radar de qualitÃ©** : MÃ©triques multidimensionnelles
11. **Table de scores** : Tableau formatÃ©
12. **Embeddings 3D** : Visualisation interactive 3D

---

## ğŸ› ï¸ Technologies UtilisÃ©es

### Machine Learning & NLP
- **PyTorch** : Framework deep learning
- **Sentence-Transformers** : Embeddings sÃ©mantiques (BERT multilingue)
- **scikit-learn** : Clustering, mÃ©triques, preprocessing
- **rank-bm25** : Algorithme BM25 pour scoring lexical

### Traitement de DonnÃ©es
- **NumPy** : Calculs numÃ©riques optimisÃ©s
- **Pandas** : Manipulation de donnÃ©es tabulaires
- **SciPy** : Statistiques avancÃ©es

### Visualisation
- **Matplotlib** : Graphiques statiques
- **Seaborn** : Visualisations statistiques

### Utilitaires
- **ftfy** : Correction d'encodage Unicode
- **langdetect** : DÃ©tection automatique de langue
- **HDBSCAN** : Clustering hiÃ©rarchique (optionnel)

---

## ğŸ¤ Contribution

Les contributions sont les bienvenues ! Pour contribuer :

1. Forkez le projet
2. CrÃ©ez une branche feature (`git checkout -b feature/amelioration`)
3. Committez vos changements (`git commit -m 'Ajout nouvelle fonctionnalitÃ©'`)
4. Poussez vers la branche (`git push origin feature/amelioration`)
5. Ouvrez une Pull Request

### Standards de code
- **Style** : Black (formatage automatique)
- **Linting** : Ruff
- **Type hints** : mypy
- **Tests** : pytest (couverture > 80%)

---

## ğŸ“ License

Ce projet est sous licence MIT. Voir le fichier [LICENSE](LICENSE) pour plus de dÃ©tails.

---

## ğŸ“§ Contact

Pour toute question ou suggestion, n'hÃ©sitez pas Ã  ouvrir une issue sur GitHub.

---

**DÃ©veloppÃ© avec â¤ï¸ pour la recherche scientifique**