# ğŸ”¬ Pipeline AvancÃ© de Tri d'Articles Scientifiques

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue.svg)](https://www.python.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Code Style](https://img.shields.io/badge/Code%20Style-Black-black.svg)](https://github.com/psf/black)

Un systÃ¨me intelligent et robuste de filtrage, tri et sÃ©lection d'articles scientifiques utilisant l'apprentissage automatique, le traitement du langage naturel (NLP) et des techniques statistiques avancÃ©es.

---

## ğŸ“‹ Table des MatiÃ¨res

- [Vue d'ensemble](#-vue-densemble)
- [FonctionnalitÃ©s](#-fonctionnalitÃ©s)
- [Architecture](#-architecture)
- [Installation](#-installation)
- [Utilisation](#-utilisation)
- [Structure du Projet](#-structure-du-projet)
- [Configuration](#-configuration)
- [RÃ©sultats et Visualisations](#-rÃ©sultats-et-visualisations)
- [Technologies UtilisÃ©es](#-technologies-utilisÃ©es)
- [Contribution](#-contribution)
- [License](#-license)

---

## ğŸ¯ Vue d'ensemble

Ce pipeline implÃ©mente un systÃ¨me de bout-en-bout pour :
- **Filtrer** et nettoyer des articles scientifiques
- **Scorer** leur pertinence par rapport Ã  une requÃªte
- **DÃ©tecter** les doublons et quasi-doublons
- **Clusteriser** les articles par similaritÃ© sÃ©mantique
- **SÃ©lectionner** les meilleurs articles en optimisant la diversitÃ© et la pertinence
- **Visualiser** les rÃ©sultats avec des graphiques interactifs

Le systÃ¨me est conÃ§u pour Ãªtre **robuste**, **sÃ©curisÃ©** et **scalable**, avec une attention particuliÃ¨re portÃ©e Ã  la validation statistique et Ã  la qualitÃ© du code.

---

## âœ¨ FonctionnalitÃ©s

### ğŸ” Analyse et Filtrage
- **Nettoyage robuste** : Sanitisation HTML, normalisation Unicode, dÃ©tection de langue
- **DÃ©tection de doublons** : Identification des doublons exacts et quasi-doublons par hashing et similaritÃ©
- **Validation de sÃ©curitÃ©** : Protection contre XSS, injection SQL, attaques DoS

### ğŸ“Š Scoring Multi-CritÃ¨res
- **BM25** : Score de pertinence lexicale
- **Embeddings sÃ©mantiques** : SimilaritÃ© cosinus avec Sentence-BERT
- **Scores combinÃ©s** : Z-scores robustes utilisant la dÃ©viation mÃ©diane absolue (MAD)

### ğŸ² Clustering Intelligent
- **DBSCAN** : Clustering avec epsilon adaptatif
- **HDBSCAN** : Clustering hiÃ©rarchique robuste (optionnel)
- **MÃ©triques de qualitÃ©** : Silhouette, Calinski-Harabasz, Davies-Bouldin

### ğŸ¯ SÃ©lection Optimale
- **Seuillage multi-mÃ©thode** : GMM, KDE, Otsu, mÃ©thode d'ensemble
- **MMR (Maximal Marginal Relevance)** : Optimisation pertinence/diversitÃ©
- **Facility Location** : SÃ©lection submodulaire pour reprÃ©sentativitÃ© maximale

### ğŸ“ˆ Visualisations
- Distributions des scores
- Analyse des seuils
- Diagrammes de flux (pipeline)
- Projections 2D/3D des embeddings
- Heatmaps de similaritÃ©
- Graphiques radar de qualitÃ©

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Articles CSV   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Preprocessing  â”‚ â† Nettoyage, normalisation, validation
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Embeddings    â”‚ â† Sentence-BERT (modÃ¨le multilingue)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Scoring     â”‚ â† BM25 + SimilaritÃ© sÃ©mantique
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Deduplication  â”‚ â† DÃ©tection doublons/quasi-doublons
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Clustering    â”‚ â† DBSCAN/HDBSCAN
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Thresholding   â”‚ â† Seuillage adaptatif multi-mÃ©thode
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      MMR        â”‚ â† SÃ©lection finale optimale
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    RÃ©sultats    â”‚ â† CSV + JSON + Visualisations
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ Installation

### PrÃ©requis
- **Python** : 3.8 ou supÃ©rieur
- **RAM** : Minimum 8 GB (16 GB recommandÃ© pour gros corpus)
- **SystÃ¨me** : Windows 10+, Linux, macOS

### Installation des dÃ©pendances

```bash
# CrÃ©er un environnement virtuel (recommandÃ©)
python -m venv venv

# Activer l'environnement
# Windows
venv\Scripts\activate
# Linux/macOS
source venv/bin/activate

# Installer les dÃ©pendances
pip install -r requirements_improved.txt

# Note : Sur Windows, si vous rencontrez des problÃ¨mes avec PyTorch :
pip install torch --index-url https://download.pytorch.org/whl/cpu
```

### Installation rapide (dÃ©pendances minimales)

```bash
pip install numpy pandas scipy scikit-learn torch sentence-transformers rank-bm25 langdetect ftfy
```

---

## ğŸ’» Utilisation

### GÃ©nÃ©ration de donnÃ©es de test

```bash
python generate_data.py --n-pos 200 --n-neg 150 --seed 42 --out data/articles_fictifs.csv
```

### ExÃ©cution du pipeline

#### MÃ©thode simple (configuration par dÃ©faut)

```bash
python process_improved.py
```

Le pipeline utilisera les paramÃ¨tres par dÃ©faut :
- RequÃªte principale : "l'effet de la lumiÃ¨re sur le comportement des chats"
- Fichier d'entrÃ©e : `data/articles_fictifs.csv`
- Fichier de sortie : `data/articles_final.csv`
- Rapport : `articles_report.json`

#### MÃ©thode avancÃ©e (configuration personnalisÃ©e)

```python
from process_improved import Config, main

# CrÃ©er une configuration personnalisÃ©e
config = Config(
    query_main="intelligence artificielle machine learning",
    input_csv="data/articles_fictifs.csv",
    output_csv="data/articles_final.csv",
    report_json="articles_report.json",
    threshold_method="ensemble",
    cluster_method="hdbscan",  # ou "dbscan", "graph_cc"
    mmr_topk=50,
    mmr_lambda=0.7,
    fusion_method="rrf",  # ou "linear_z", "rank_pct"
    batch_size=16,
    use_gpu=False,  # Mettre Ã  True si GPU disponible
)

# ExÃ©cuter le pipeline
report = main(config)
```

### GÃ©nÃ©ration des visualisations

```bash
python generate_visualizations.py
```

Ou avec des chemins personnalisÃ©s :

```bash
python visualize.py --report articles_report.json --csv data/articles_final.csv --output visualizations
```

Les visualisations seront gÃ©nÃ©rÃ©es dans le dossier `visualizations/`.

---

## ğŸ“ Structure du Projet

```
projet_filtre/
â”œâ”€â”€ ğŸ“„ README.md                          # Documentation principale
â”œâ”€â”€ ğŸ“„ requirements_improved.txt          # DÃ©pendances Python
â”œâ”€â”€ ğŸ“„ .gitignore                         # Fichiers ignorÃ©s par Git
â”œâ”€â”€ ğŸ generate_data.py                   # GÃ©nÃ©rateur d'articles fictifs pour tests
â”œâ”€â”€ ğŸ process_improved.py                # Pipeline principal (cÅ“ur du systÃ¨me, ~1850 lignes)
â”œâ”€â”€ ğŸ generate_visualizations.py         # Script wrapper pour gÃ©nÃ©rer les graphiques
â”œâ”€â”€ ğŸ visualize.py                       # Module de visualisation (classe PipelineVisualizer)
â”œâ”€â”€ ğŸ“ data/                             # DonnÃ©es du projet
â”‚   â”œâ”€â”€ ğŸ“Š articles_fictifs.csv           # DonnÃ©es d'entrÃ©e (gÃ©nÃ©rÃ©es par generate_data.py)
â”‚   â””â”€â”€ ğŸ“Š articles_final.csv             # RÃ©sultats finaux du pipeline
â”œâ”€â”€ ğŸ“ .cache_embeddings/                # Cache des embeddings (crÃ©Ã© automatiquement)
â”œâ”€â”€ ğŸ“Š articles_final_embeddings.npy      # Embeddings sauvegardÃ©s des articles sÃ©lectionnÃ©s
â”œâ”€â”€ ğŸ“‹ articles_report.json               # Rapport dÃ©taillÃ© JSON avec mÃ©triques
â”œâ”€â”€ ğŸ“ pipeline.log                       # Logs d'exÃ©cution structurÃ©s
â””â”€â”€ ğŸ“ visualizations/                    # Graphiques gÃ©nÃ©rÃ©s
    â”œâ”€â”€ 01_score_distributions.png       # Distribution des scores (embedding, BM25, final)
    â”œâ”€â”€ 02_threshold_analysis.png         # Analyse du seuillage automatique
    â”œâ”€â”€ 03_pipeline_flow.png              # Diagramme de flux (entonnoir de filtrage)
    â”œâ”€â”€ 04_clusters_2d.png                # Projection t-SNE des clusters
    â”œâ”€â”€ 05_top_articles.png               # Top articles par score
    â”œâ”€â”€ 06_score_correlation.png          # Matrice de corrÃ©lation entre scores
    â”œâ”€â”€ 07_similarity_heatmap.png         # Heatmap de similaritÃ© entre articles
    â”œâ”€â”€ 08_text_lengths.png                # Distribution des longueurs de texte
    â”œâ”€â”€ 09_cluster_boxplots.png           # Boxplots des scores par cluster
    â”œâ”€â”€ 10_quality_radar.png              # Radar chart des mÃ©triques de qualitÃ©
    â”œâ”€â”€ 11_score_table.png                # Table comparative des mÃ©thodes de scoring
    â”œâ”€â”€ 12_embeddings_3d.png              # Projection 3D des embeddings (PCA)
    â””â”€â”€ README.md                         # Documentation des visualisations
```

### Fichiers gÃ©nÃ©rÃ©s automatiquement

Lors de l'exÃ©cution du pipeline, les fichiers suivants sont crÃ©Ã©s :
- `articles_report.json` : Rapport complet avec statistiques, mÃ©triques et diagnostics
- `data/articles_final.csv` : Articles sÃ©lectionnÃ©s avec scores dÃ©taillÃ©s
- `articles_final_embeddings.npy` : Embeddings des articles finaux (pour visualisation 3D)
- `pipeline.log` : Logs d'exÃ©cution (format structurÃ©)
- `.cache_embeddings/` : Cache des embeddings pour Ã©viter les recalculs

---

## âš™ï¸ Configuration

Le pipeline est hautement configurable via la classe `Config` dans `process_improved.py` :

### ParamÃ¨tres principaux

| ParamÃ¨tre | Description | Valeurs possibles | DÃ©faut |
|-----------|-------------|-------------------|--------|
| `query_main` | RequÃªte de recherche principale | string | `"l'effet de la lumiÃ¨re sur le comportement des chats"` |
| `input_csv` | Fichier CSV d'entrÃ©e | chemin relatif/absolu | `"data/articles_fictifs.csv"` |
| `output_csv` | Fichier CSV de sortie | chemin relatif/absolu | `"data/articles_final.csv"` |
| `threshold_method` | MÃ©thode de seuillage | `"ensemble"`, `"gmm"`, `"kde"`, `"otsu"` | `"ensemble"` |
| `cluster_method` | Algorithme de clustering | `"hdbscan"`, `"dbscan"`, `"graph_cc"` | `"hdbscan"` |
| `fusion_method` | MÃ©thode de fusion BM25/embedding | `"rrf"`, `"linear_z"`, `"rank_pct"` | `"rrf"` |
| `mmr_topk` | Nombre d'articles finaux | int | `50` |
| `mmr_lambda` | Balance pertinence/diversitÃ© | 0.0-1.0 | `0.7` |
| `min_abstract_len` | Longueur minimale d'abstract | int | `30` |
| `dedup_threshold` | Seuil de dÃ©duplication | 0.0-1.0 | `0.985` |
| `batch_size` | Taille de batch pour embeddings | int | `16` |
| `use_gpu` | Utiliser GPU si disponible | bool | `False` |

### ParamÃ¨tres avancÃ©s

```python
config = Config(
    # ModÃ¨le d'embeddings
    model_id="intfloat/multilingual-e5-small",  # ModÃ¨le Sentence-BERT
    
    # Pooling du body (longs textes)
    body_pooling="attn",  # "attn" (attention query-aware) ou "maxmean"
    body_chunk_size=600,  # Taille des chunks
    body_chunk_stride=400,  # Pas de fenÃªtre glissante
    
    # Poids pour scoring multi-champs
    w_title=0.5,    # Poids titre
    w_abs=0.3,      # Poids abstract
    w_body=0.2,     # Poids body
    
    # Fusion des scores
    fusion_bm25_weight=0.3,  # Poids BM25
    fusion_embed_weight=0.7, # Poids embeddings
    
    # Clustering HDBSCAN
    hdbscan_min_cluster_size=5,
    hdbscan_min_samples=2,
    hdbscan_cluster_selection_method="eom",  # "eom" ou "leaf"
    
    # SÃ©curitÃ©
    max_text_len=1_000_000,  # Limite contre attaques DoS
    allowed_langs=("fr", "en"),  # Langues acceptÃ©es
)
```

### Exemple de configuration personnalisÃ©e

```python
from process_improved import Config, main

config = Config(
    query_main="machine learning deep learning neural networks",
    input_csv="data/mes_articles.csv",
    output_csv="data/resultats.csv",
    threshold_method="gmm",  # Utiliser GMM au lieu d'ensemble
    cluster_method="dbscan",  # DBSCAN classique
    mmr_topk=100,  # SÃ©lectionner 100 articles
    mmr_lambda=0.6,  # Plus de diversitÃ© (lambda plus bas)
    use_gpu=True,  # AccÃ©lÃ©rer avec GPU
    batch_size=32,  # Batch plus grand si GPU disponible
)

report = main(config)
```

---

## ğŸ“Š RÃ©sultats et Visualisations

### Fichiers de sortie

#### `data/articles_final.csv`
Articles sÃ©lectionnÃ©s avec scores et mÃ©tadonnÃ©es :
- Colonnes originales : `url`, `title`, `abstract`, `body`, `lang_hint`, `author`, `journal`, `published_at`, `doi`, `quality_type`
- Scores calculÃ©s :
  - `score_title` : Score de similaritÃ© du titre
  - `score_abstract` : Score de similaritÃ© de l'abstract
  - `score_body` : Score de similaritÃ© du corps
  - `score_embed` : Score embedding combinÃ© (pondÃ©rÃ©)
  - `score_bm25` : Score BM25 lexical
  - `score` : Score final aprÃ¨s fusion
- MÃ©tadonnÃ©es de traitement :
  - `cluster_id` : ID du cluster (ou -1 pour bruit)
  - `rank` : Rang final aprÃ¨s sÃ©lection MMR

#### `articles_report.json`
Rapport dÃ©taillÃ© incluant :
- **MÃ©tadonnÃ©es** : Version, timestamps, durÃ©e d'exÃ©cution
- **Configuration** : Tous les paramÃ¨tres utilisÃ©s
- **Compteurs** : Nombre d'articles Ã  chaque Ã©tape du pipeline
- **Seuils** : MÃ©thode utilisÃ©e, valeur, mÃ©tadonnÃ©es (pour ensemble : poids de chaque mÃ©thode)
- **Clustering** : MÃ©triques (silhouette, Calinski-Harabasz, Davies-Bouldin), nombre de clusters
- **SÃ©lection** : Quotas par cluster, statistiques, mÃ©thode MMR/Facility Location
- **Statistiques** : Min/max/moyenne/std des scores, diversitÃ© cosine
- **Longueurs de texte** : Statistiques pour titre, abstract, body
- **Distributions par cluster** : Scores moyens par cluster
- **Matrice de similaritÃ©** : SimilaritÃ© entre articles sÃ©lectionnÃ©s (si < 100 articles)

#### `articles_final_embeddings.npy`
Tableau NumPy (N, D) contenant les embeddings L2-normalisÃ©s des articles sÃ©lectionnÃ©s. UtilisÃ© pour la visualisation 3D.

### Visualisations disponibles

1. **Distributions des scores** : Histogrammes BM25, sÃ©mantique, combinÃ©
2. **Analyse des seuils** : MÃ©thodes de seuillage comparÃ©es
3. **Pipeline flow** : Diagramme de flux Sankey
4. **Clusters 2D** : Projection t-SNE/UMAP
5. **Top articles** : Barres horizontales des meilleurs scores
6. **CorrÃ©lations** : Scatter plots entre scores
7. **Heatmap de similaritÃ©** : Matrice de similaritÃ© sÃ©mantique
8. **Longueurs de texte** : Distribution des longueurs
9. **Boxplots par cluster** : Scores par cluster
10. **Radar de qualitÃ©** : MÃ©triques multidimensionnelles
11. **Table de scores** : Tableau formatÃ©
12. **Embeddings 3D** : Visualisation interactive 3D

---

## ğŸ› ï¸ Technologies UtilisÃ©es

### Machine Learning & NLP
- **PyTorch** : Framework deep learning
- **Sentence-Transformers** : Embeddings sÃ©mantiques (BERT multilingue)
- **scikit-learn** : Clustering, mÃ©triques, preprocessing
- **rank-bm25** : Algorithme BM25 pour scoring lexical

### Traitement de DonnÃ©es
- **NumPy** : Calculs numÃ©riques optimisÃ©s
- **Pandas** : Manipulation de donnÃ©es tabulaires
- **SciPy** : Statistiques avancÃ©es

### Visualisation
- **Matplotlib** : Graphiques statiques
- **Seaborn** : Visualisations statistiques

### Utilitaires
- **ftfy** : Correction d'encodage Unicode
- **langdetect** : DÃ©tection automatique de langue
- **HDBSCAN** : Clustering hiÃ©rarchique (optionnel)

---

## ğŸ¤ Contribution

Les contributions sont les bienvenues ! Pour contribuer :

1. Forkez le projet
2. CrÃ©ez une branche feature (`git checkout -b feature/amelioration`)
3. Committez vos changements (`git commit -m 'Ajout nouvelle fonctionnalitÃ©'`)
4. Poussez vers la branche (`git push origin feature/amelioration`)
5. Ouvrez une Pull Request

### Standards de code
- **Style** : Black (formatage automatique)
- **Linting** : Ruff
- **Type hints** : mypy
- **Tests** : pytest (couverture > 80%)

---

## ğŸ“ License

Ce projet est sous licence MIT. Voir le fichier [LICENSE](LICENSE) pour plus de dÃ©tails.

---

## ğŸ› DÃ©pannage

### ProblÃ¨mes courants

**Erreur : "HDBSCAN non disponible"**
```bash
pip install hdbscan
```

**Erreur avec torch sur Windows**
```bash
pip install torch --index-url https://download.pytorch.org/whl/cpu
```

**MÃ©moire insuffisante**
- RÃ©duisez `batch_size` dans la config (par exemple `8` au lieu de `16`)
- Traitez les donnÃ©es par lots en divisant le CSV d'entrÃ©e

**Cache des embeddings corrompu**
```bash
# Supprimer le cache (sera rÃ©gÃ©nÃ©rÃ© automatiquement)
rm -rf .cache_embeddings  # Linux/Mac
rmdir /s .cache_embeddings  # Windows PowerShell
```

**Visualisations manquantes**
- VÃ©rifiez que `articles_report.json` et `data/articles_final.csv` existent
- ExÃ©cutez d'abord le pipeline : `python process_improved.py`
- Puis gÃ©nÃ©rez les visualisations : `python generate_visualizations.py`

---

## ğŸ“§ Contact

Pour toute question ou suggestion, n'hÃ©sitez pas Ã  ouvrir une issue sur GitHub.

---

**DÃ©veloppÃ© avec â¤ï¸ pour la recherche scientifique**