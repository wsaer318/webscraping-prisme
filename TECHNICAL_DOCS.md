# ğŸ› ï¸ Documentation Technique - PRISMA Review Manager

## ğŸ—ï¸ Architecture du Projet

Le projet est une application web **Streamlit** structurÃ©e en plusieurs pages, s'appuyant sur une base de donnÃ©es **SQLite** et des modules Python pour la logique mÃ©tier (Scraping, NLP, Analytics).

### Structure des Dossiers

```
projet_prisma/
â”œâ”€â”€ app.py                      # Point d'entrÃ©e (Dashboard)
â”œâ”€â”€ pages/                      # Pages de l'application Streamlit
â”‚   â”œâ”€â”€ 1_Recherche.py          # Interface de collecte (Scraping)
â”‚   â”œâ”€â”€ 2_Screening.py          # Interface de tri (Titre/Abstract)
â”‚   â”œâ”€â”€ 3_Eligibilite.py        # Interface de revue (Full Text)
â”‚   â”œâ”€â”€ 4_Analyse.py            # Dashboard analytique & Reporting
â”‚   â””â”€â”€ 0_Base_de_donnees.py    # Explorateur de donnÃ©es brut
â”œâ”€â”€ src/                        # Logique mÃ©tier (Package Python)
â”‚   â”œâ”€â”€ collection/             # Modules de scraping (arXiv, PubMed, etc.)
â”‚   â”œâ”€â”€ database.py             # ModÃ¨les SQLAlchemy & Connexion DB
â”‚   â”œâ”€â”€ advanced_sorting.py     # Moteur de ranking IA (Embeddings)
â”‚   â”œâ”€â”€ concept_filter.py       # Moteur de filtrage par mots-clÃ©s
â”‚   â”œâ”€â”€ pdf_retriever.py        # TÃ©lÃ©chargement automatique de PDFs
â”‚   â”œâ”€â”€ analytics.py            # Calcul des statistiques
â”‚   â”œâ”€â”€ exporters.py            # Export CSV/Excel/BibTeX
â”‚   â””â”€â”€ ui_utils.py             # Utilitaires UI (CSS Premium)
â”œâ”€â”€ data/                       # Stockage des donnÃ©es
â”‚   â”œâ”€â”€ prisma.db               # Base de donnÃ©es SQLite
â”‚   â””â”€â”€ pdfs/                   # Stockage des fichiers PDF
â”œâ”€â”€ static/                     # Ressources statiques
â”‚   â””â”€â”€ styles/                 # Fichiers CSS
â””â”€â”€ requirements.txt            # DÃ©pendances du projet
```

---

## ğŸ—„ï¸ SchÃ©ma de Base de DonnÃ©es

L'application utilise **SQLAlchemy** (ORM) avec **SQLite**.

### 1. `SearchSession` (Sessions de recherche)
Regroupe les articles importÃ©s lors d'une mÃªme opÃ©ration de recherche.
- `id` (PK): Identifiant unique
- `query`: RequÃªte utilisÃ©e
- `created_at`: Date de crÃ©ation
- `num_results`: Nombre d'articles trouvÃ©s
- `status`: Ã‰tat de la session (ACTIVE, ARCHIVED)

### 2. `Article` (Table principale)
Contient toutes les mÃ©tadonnÃ©es et l'Ã©tat de chaque article.
- **Identification**
  - `id` (PK), `title`, `authors`, `year`, `source`, `doi`, `link`
- **Contenu**
  - `abstract`: RÃ©sumÃ©
  - `full_text`: Texte complet extrait
  - `pdf_path`: Chemin local du fichier PDF
- **Statut PRISMA (`status`)**
  - `IDENTIFIED`: ImportÃ© brut
  - `EXCLUDED_SEMANTIC_FILTER`: RejetÃ© par le prÃ©-tri sÃ©mantique
  - `SCREENED_IN`: Retenu aprÃ¨s lecture Titre/Abstract
  - `EXCLUDED_SCREENING`: RejetÃ© aprÃ¨s lecture Titre/Abstract
  - `EXCLUDED_ELIGIBILITY`: RejetÃ© aprÃ¨s lecture Texte Complet
  - `INCLUDED`: Inclus dans la revue finale
- **Analyse IA**
  - `relevance_score`: Score de pertinence (0-1) calculÃ© par Cross-Encoder
  - `suggested_reason`: Justification suggÃ©rÃ©e par l'IA
  - `ia_metadata`: DÃ©tails techniques (JSON)

### 3. `ArticleHistory` (TraÃ§abilitÃ©)
Enregistre chaque changement d'Ã©tat pour l'audit.
- `article_id` (FK), `previous_status`, `new_status`, `timestamp`, `user`

### 4. `ExclusionCriteria` & `EligibilityCriteria`
CritÃ¨res configurables pour justifier les exclusions.

---

## ğŸ§  Moteurs d'Analyse (IA & NLP)

### 1. Ranking SÃ©mantique (`src.advanced_sorting`)
Utilise `sentence-transformers` pour trier les articles par pertinence.
- **ModÃ¨le Bi-Encoder** (`paraphrase-MiniLM-L3-v2`): Pour l'encodage rapide des vecteurs.
- **Cross-Encoder** (optionnel): Pour le re-ranking prÃ©cis.

### 2. Filtrage par Concepts (`src.concept_filter`)
Permet de filtrer les articles contenant des mots-clÃ©s spÃ©cifiques.
- Supporte les opÃ©rateurs boolÃ©ens (AND/OR).
- Recherche dans le Titre, l'Abstract et le Full Text (via chunking).

### 3. Extraction de PDF (`src.pdf_retriever`)
- Tente de tÃ©lÃ©charger le PDF via `Unpaywall` (API gratuite) ou `ArXiv`.
- Utilise `PyMuPDF` (fitz) pour extraire le texte brut du PDF pour l'analyse.

---

## ğŸ’» Guide de DÃ©veloppement

### Installation de l'environnement
```bash
python -m venv .venv
.venv\Scripts\activate
pip install -r requirements.txt
```

### Ajouter une nouvelle page
1. CrÃ©er un fichier `pages/X_NomPage.py`.
2. Importer `st` et `load_premium_css`.
3. Appeler `load_premium_css()` au dÃ©but.

### Modifier le modÃ¨le de donnÃ©es
1. Ã‰diter `src/database.py`.
2. **Attention**: SQLite ne supporte pas bien les migrations `ALTER TABLE`. Pour des changements majeurs, il est souvent plus simple de supprimer `prisma.db` (si en dev) ou d'utiliser un script de migration manuel (crÃ©er nouvelle table, copier donnÃ©es, renommer).
