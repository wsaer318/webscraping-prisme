# -*- coding: utf-8 -*-
"""
G√©n√©ration de crit√®res d'exclusion via LLM (Hugging Face API)
Architecture: Crit√®res universels + Crit√®res contextuels g√©n√©r√©s par IA
"""
import json
import os
import re
from huggingface_hub import InferenceClient
from dotenv import load_dotenv

# Charger les variables d'environnement
load_dotenv()


def generate_exclusion_criteria(query: str) -> list:
    """
    G√©n√®re des crit√®res d'exclusion pour une requ√™te PRISMA.
    Combine crit√®res universels + crit√®res contextuels g√©n√©r√©s par IA.
    
    Args:
        query: La requ√™te de recherche (ex: "machine learning")
        
    Returns:
        Liste de dictionnaires {label, description}
    """
    
    # Crit√®res de base UNIVERSELS (toujours pr√©sents)
    base_criteria = [
        {
            "label": "Langue",
            "description": "Full text not available in English or French"
        },
        {
            "label": "Type publication",
            "description": "Editorial, opinion piece, book chapter, conference abstract, or non-peer-reviewed content"
        }
    ]
    
    # R√©cup√©rer le token HF
    hf_token = os.getenv("HF_TOKEN")
    
    if not hf_token:
        print("‚ö†Ô∏è HF_TOKEN non trouv√© dans .env - Utilisation de crit√®res par d√©faut")
        return base_criteria + _get_contextual_defaults(query)
    
    try:
        # Initialiser le client Hugging Face
        client = InferenceClient(token=hf_token)
        
        # Prompt LIBRE pour g√©n√©rer des crit√®res contextuels
        prompt = f"""You are a research assistant analyzing a PRISMA systematic review query.

QUERY: "{query}"

Task: Generate 2-3 CONTEXTUAL exclusion criteria specific to this research topic.
Do NOT generate generic criteria (language, publication type - already handled).

Focus on:
- Topic-specific scope boundaries (what IS and ISN'T in scope)
- Domain-specific methodological requirements  
- Population/setting/context relevance (if applicable)

Be creative and analyze the query deeply. Think about what makes an article truly relevant vs off-topic for THIS specific research.

Output format (JSON only, no markdown):
[
  {{"label": "French label (2-4 words)", "description": "Detailed English description for AI classification"}},
  {{"label": "...", "description": "..."}},
  {{"label": "...", "description": "..."}}
]

Example for "machine learning healthcare":
[
  {{"label": "Pas d'application ML", "description": "Article discusses healthcare but does not apply or develop machine learning methods"}},
  {{"label": "ML th√©orique uniquement", "description": "Pure theoretical ML without healthcare application or validation"}},
  {{"label": "Donn√©es non-sant√©", "description": "Machine learning applied to non-healthcare domains (finance, robotics, etc.)"}}
]

Now generate for: "{query}" """

        print(f"ü§ñ G√©n√©ration de crit√®res contextuels pour : '{query}'...")
        
        # Appel API
        messages = [{"role": "user", "content": prompt}]
        response = client.chat_completion(
            messages=messages,
            model="meta-llama/Llama-3.2-3B-Instruct",
            max_tokens=500,
            temperature=0.4  # Un peu de cr√©ativit√©
        )
        
        response_text = response.choices[0].message.content
        
        # Parser avec robustesse
        contextual_criteria = _parse_llm_response(response_text)
        
        # Combiner base + contextuels
        all_criteria = base_criteria + contextual_criteria
        print(f"‚úì {len(all_criteria)} crit√®res g√©n√©r√©s ({len(base_criteria)} base + {len(contextual_criteria)} contextuels)")
        
        return all_criteria
        
    except Exception as e:
        print(f"‚ùå Erreur lors de la g√©n√©ration LLM : {e}")
        print(f"‚Üí Utilisation de crit√®res par d√©faut")
        return base_criteria + _get_contextual_defaults(query)


def _parse_llm_response(response_text: str) -> list:
    """Parse la r√©ponse LLM avec plusieurs strat√©gies de nettoyage"""
    
    response_clean = response_text.strip()
    
    # Strat√©gie 1: Retirer markdown
    if "```json" in response_clean:
        response_clean = response_clean.split("```json")[1].split("```")[0].strip()
    elif "```" in response_clean:
        response_clean = response_clean.split("```")[1].split("```")[0].strip()
    
    # Strat√©gie 2: Extraire le JSON
    json_match = re.search(r'\[\s*\{.*?\}\s*\]', response_clean, re.DOTALL)
    if json_match:
        response_clean = json_match.group(0)
    
    try:
        criteria = json.loads(response_clean)
    except json.JSONDecodeError as e:
        # Nettoyer les guillemets probl√©matiques
        response_clean = response_clean.replace('""', '"')
        try:
            criteria = json.loads(response_clean)
        except:
            raise ValueError(f"Impossible de parser: {e}\nContenu: {response_clean[:200]}")
    
    # Valider
    if not isinstance(criteria, list):
        raise ValueError("R√©ponse LLM n'est pas une liste")
    
    for c in criteria:
        if not isinstance(c, dict) or "label" not in c or "description" not in c:
            raise ValueError(f"Crit√®re invalide: {c}")
    
    return criteria


def _get_contextual_defaults(query: str) -> list:
    """Crit√®res contextuels par d√©faut si l'API √©choue"""
    return [
        {
            "label": f"Hors sujet",
            "description": f"Article not primarily about {query} or significantly deviates from the core research topic"
        },
        {
            "label": "Revue/Synth√®se",
            "description": "Literature review, systematic review, meta-analysis, or synthesis without original empirical data"
        },
        {
            "label": "M√©thodologie",
            "description": "Purely theoretical article without empirical validation, experimental results, or data analysis"
        }
    ]


if __name__ == "__main__":
    # Test
    test_query = "machine learning"
    criteria = generate_exclusion_criteria(test_query)
    
    print("\n" + "="*60)
    print(f"Crit√®res g√©n√©r√©s pour : {test_query}")
    print("="*60)
    for i, c in enumerate(criteria, 1):
        print(f"\n{i}. {c['label']}")
        print(f"   ‚Üí {c['description']}")
